{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
      "display_name": "Python 3.8.2 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "name": "AgeClassification(TopicControl).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D2BmDqJyIA7"
      },
      "source": [
        "# =============================================================================\n",
        "# Carico i file\n",
        "# =============================================================================\n",
        "train_file = r'data/training.txt'\n",
        "train_url=r'data/training1.csv'\n",
        "test_file = r'data/test.txt'\n",
        "test_url = r'data/test1.csv'\n",
        "delimiter = ','\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVzRoV2yO1e"
      },
      "source": [
        "import csv\n",
        "x_train = list()\n",
        "y_train = list()\n",
        "topic_train = list()\n",
        "with open(train_url, encoding='utf-8', newline='') as infile:\n",
        "    reader = csv.reader(infile, delimiter=delimiter)\n",
        "    for row in reader:\n",
        "        x_train.append(row[5])\n",
        "        y_train.append(row[2])\n",
        "        topic_train.append(row[3])\n",
        "\n",
        "x_test = list()\n",
        "y_test = list()\n",
        "topic_test = list()\n",
        "with open(test_url, encoding='utf-8', newline='') as infile:\n",
        "    reader = csv.reader(infile, delimiter=delimiter)\n",
        "    for row in reader:\n",
        "        x_test.append(row[5])\n",
        "        y_test.append(row[2])\n",
        "        topic_test.append(row[3])\n",
        "        \n",
        "len(x_train),len(y_train),len(x_test),len(y_test)\n",
        "y_train.pop(0) # elimino il primo elemento che è la parola \"gender\"\n",
        "y_test.pop(0) # elimino il primo elemento che è la parola \"gender\"\n",
        "set(y_train)\n",
        "sample_idx = 10\n",
        "\n",
        "x_train.pop(0) # elimino il primo elemento che è la parola \"post\"\n",
        "x_test.pop(0) # elimino il primo elemento che è la parola \"post\"\n",
        "x_train[sample_idx]\n",
        "y_train[sample_idx]\n",
        "\n",
        "topic_train.pop(0) # elimino il primo elemento che è \"topic\"\n",
        "topic_test.pop(0) # elimino il primo elemento che è \"topic\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX06oDOjyO6O"
      },
      "source": [
        "# =============================================================================\n",
        "# Seleziono il topic            commentare questa parte per prendere tutti topic\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "topics = df[\"topic\"].unique()\n",
        "print(topics)\n",
        "from collections import Counter\n",
        "Counter(df[\"topic\"])\n",
        "# Seleziono il training set\n",
        "indices = [i for i, x in enumerate(topic_train) if x == \"SPORTS\"] \n",
        "x_train = [x_train[i] for i in indices]\n",
        "y_train = [y_train[i] for i in indices]\n",
        "# len(x_train), len(y_train)\n",
        "print(\"Lunghezza del training set: \", len(x_train))\n",
        "print(\"Percentuale di 0-19 nel training set: \", round(y_train.count(\"0-19\") / len(y_train), 3))\n",
        "print(\"Percentuale di 20-29 nel training set: \", round(y_train.count(\"20-29\") / len(y_train), 3))\n",
        "print(\"Percentuale di 30-39 nel training set: \", round(y_train.count(\"30-39\") / len(y_train), 3))\n",
        "print(\"Percentuale di 40-49 nel training set: \", round(y_train.count(\"40-49\") / len(y_train), 3))\n",
        "print(\"Percentuale di 50-100 nel training set: \", round(y_train.count(\"50-100\") / len(y_train), 3))\n",
        "\n",
        "# Seleziono il test set\n",
        "indices = [i for i, x in enumerate(topic_test) if x == \"SPORTS\"]\n",
        "x_test = [x_test[i] for i in indices]\n",
        "y_test = [y_test[i] for i in indices]\n",
        "# len(x_test), len(y_test)\n",
        "print(\"Lunghezza del test set: \", len(x_test))\n",
        "print(\"Percentuale di 0-19 nel test set: \", round(y_test.count(\"0-19\") / len(y_test), 3))\n",
        "print(\"Percentuale di 20-29 nel test set: \", round(y_test.count(\"20-29\") / len(y_test), 3))\n",
        "print(\"Percentuale di 30-39 nel test set: \", round(y_test.count(\"30-39\") / len(y_test), 3))\n",
        "print(\"Percentuale di 40-49 nel test set: \", round(y_test.count(\"40-49\") / len(y_test), 3))\n",
        "print(\"Percentuale di 50-100 nel test set: \", round(y_test.count(\"50-100\") / len(y_test), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufCgZVbQyO8g"
      },
      "source": [
        "# =============================================================================\n",
        "# Operazioni sul testo\n",
        "# =============================================================================\n",
        "# Rendo minuscola la prima parola dopo il punto\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Elimino la parola \"post\"\n",
        "regex = re.compile(\"\\\\bpost\\\\b\")\n",
        "for i in range(0, len(x_train)):\n",
        "    x_train[i] = regex.sub('', x_train[i])\n",
        "for i in range(0, len(x_test)):\n",
        "    x_test[i] = regex.sub('', x_test[i])\n",
        "# Elimino la punteggiatura\n",
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "for i in range(0, len(x_train)):\n",
        "    x_train[i] = regex.sub('', x_train[i])\n",
        "for i in range(0, len(x_test)):\n",
        "    x_test[i] = regex.sub('', x_test[i])\n",
        "# Elimino i numeri\n",
        "regex = re.compile(\"[0-9]+\")\n",
        "for i in range(0, len(x_train)):\n",
        "    x_train[i] = regex.sub('', x_train[i])\n",
        "for i in range(0, len(x_test)):\n",
        "    x_test[i] = regex.sub('', x_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_iL7K_FyO_A"
      },
      "source": [
        "# =============================================================================\n",
        "# Funzioni\n",
        "# =============================================================================\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "stopword_list = stopwords.words('italian')\n",
        "\n",
        "from collections import defaultdict\n",
        "tag_map = defaultdict(lambda : wordnet.NOUN)\n",
        "tag_map['J'] = wordnet.ADJ\n",
        "tag_map['V'] = wordnet.VERB\n",
        "tag_map['R'] = wordnet.ADV\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "doc_counter = 0\n",
        "def reset_counter():\n",
        "    global doc_counter\n",
        "    doc_counter = 0\n",
        "\n",
        "def increase_counter():\n",
        "    global doc_counter\n",
        "    doc_counter += 1\n",
        "    if doc_counter % 100 == 0:\n",
        "        print(doc_counter)\n",
        "\n",
        "def nltk_ngram_tokenizer(text):\n",
        "    increase_counter()\n",
        "\n",
        "    # tokens, skipping stopwords\n",
        "    tokens = [token for token in word_tokenize(text) if token not in stopword_list]\n",
        "\n",
        "    # per creare gli ngrams\n",
        "    bigrams = ['BI_'+w1+'_'+w2 for w1,w2 in nltk.ngrams(tokens,2)]\n",
        "    trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(tokens,3)]\n",
        "\n",
        "    all_tokens = list()\n",
        "    all_tokens.extend(tokens)\n",
        "    all_tokens.extend(bigrams)\n",
        "    all_tokens.extend(trigrams)\n",
        "    return all_tokens\n",
        "\n",
        "def nltk_nlp_tokenizer(text):\n",
        "    increase_counter()\n",
        "\n",
        "    # tokens, skipping stopwords\n",
        "    tokens = [token for token in word_tokenize(text) if token not in stopword_list]\n",
        "\n",
        "    # lemmatized tokens\n",
        "    lemmas = list()\n",
        "    for token, tag in pos_tag(tokens):\n",
        "  \t    lemmas.append('LEMMA_'+lemmatizer.lemmatize(token, tag_map[tag[0]]))\n",
        "\n",
        "    # nltk function per creare gli ngrams\n",
        "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas,2)]\n",
        "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas,3)]\n",
        "\n",
        "    all_tokens = list()\n",
        "    all_tokens.extend(lemmas)\n",
        "    all_tokens.extend(lemma_bigrams)\n",
        "    all_tokens.extend(lemma_trigrams)\n",
        "    return all_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDgmwjveyPBh"
      },
      "source": [
        "# Rendo la risposta binaria\n",
        "import numpy as np\n",
        "# y_train[sample_idx] è una delle due classi, nel nostro caso M. Quando vado a fare y_train == y_train[sample_idx], in pratica\n",
        "# metto TRUE per i maschi (M) e FALSE per le femmine (F).\n",
        "y_train_bin = np.asarray(y_train)==y_train[sample_idx]\n",
        "y_test_bin = np.asarray(y_test)==y_train[sample_idx]\n",
        "y_train_bin,y_test_bin\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "# vect = CountVectorizer(analyzer=nltk_ngram_tokenizer, min_df=5)  # tokenization and frequency count\n",
        "# vect = CountVectorizer(analyzer=nltk_n_gram_tokenizer)  \n",
        "# vect = CountVectorizer(analyzer=nltk_nlp_tokenizer, min_df=5)  \n",
        "vect = CountVectorizer(analyzer = nltk_nlp_tokenizer, min_df=5) # Passiamo la funzione spacy_nlp_tokenizer per ottenere sia parole singole che n-grams\n",
        "reset_counter()\n",
        "X_train_tok = vect.fit_transform(x_train)\n",
        "reset_counter()\n",
        "X_test_tok = vect.transform(x_test)\n",
        "\n",
        "len(vect.vocabulary_)\n",
        "X_train_tok[:5]\n",
        "print(X_train_tok[:5])\n",
        "vect.inverse_transform(X_train_tok[:5])\n",
        "for feat,freq in zip(vect.inverse_transform(X_train_tok[:5])[1],X_train_tok[:5].data):\n",
        "  print(feat,freq)\n",
        "\n",
        "# FEATURE SELECTION\n",
        "bin_sel = SelectKBest(chi2, k=150)\n",
        "bin_sel.fit(X_train_tok,y_train_bin)\n",
        "X_train_sel_bin = bin_sel.transform(X_train_tok)\n",
        "X_test_sel_bin = bin_sel.transform(X_test_tok)\n",
        "\n",
        "bin_sel.get_support()\n",
        "X_train_sel_bin\n",
        "print(X_train_sel_bin[:5])\n",
        "print(vect.inverse_transform(bin_sel.inverse_transform(X_train_sel_bin[:5])))\n",
        "\n",
        "# PESI CON TF-IDF\n",
        "tfidf = TfidfTransformer()\n",
        "tfidf.fit(X_train_sel_bin)\n",
        "X_train_vec_bin = tfidf.transform(X_train_sel_bin)\n",
        "X_test_vec_bin =tfidf.transform(X_test_sel_bin)\n",
        "\n",
        "print(X_train_vec_bin[:5])\n",
        "for feat,weight,freq in zip(vect.inverse_transform(bin_sel.inverse_transform(X_train_vec_bin[:5]))[1],X_train_vec_bin[:5].data,X_train_sel_bin[:5].data):\n",
        "  print(feat,weight,freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i97abvXbyPED"
      },
      "source": [
        "# =============================================================================\n",
        "# Linear SVC\n",
        "# =============================================================================\n",
        "pipeline = Pipeline([\n",
        "    ('sel', SelectKBest(chi2, k=150)),  # feature selection\n",
        "    ('tfidf', TfidfTransformer()),  # weighting\n",
        "    ('learner', LinearSVC())  # learning algorithm\n",
        "])\n",
        "\n",
        "classifier = pipeline.fit(X_train_tok,y_train)\n",
        "predictions = classifier.predict(X_test_tok)\n",
        "correct = 0\n",
        "for prediction,true_label in zip(predictions, y_test):\n",
        "    if prediction==true_label:\n",
        "        correct += 1\n",
        "print(correct/len(predictions))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print('Classification report per il LinearSVC:')\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp4uA8qnyPHR"
      },
      "source": [
        "# =============================================================================\n",
        "# One Vs One\n",
        "# =============================================================================\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('sel', SelectKBest(chi2, k=150)),  # feature selection\n",
        "    ('tfidf', TfidfTransformer()),  # weighting\n",
        "    ('learner', OneVsOneClassifier(LinearSVC()))  # learning algorithm\n",
        "])\n",
        "\n",
        "classifier = pipeline.fit(X_train_tok,y_train)\n",
        "predictions = classifier.predict(X_test_tok)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print('Classification report del OneVsOne con il LinearSVC:')\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xewMZN9XyPLh"
      },
      "source": [
        "# =============================================================================\n",
        "# Logistic Regression \n",
        "# =============================================================================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('sel', SelectKBest(chi2, k=150)),  # feature selection\n",
        "    ('tfidf', TfidfTransformer()),  # weighting\n",
        "    ('learner', LogisticRegression(solver=\"newton-cg\",multi_class=\"multinomial\", class_weight=\"balanced\"))  # learning algorithm\n",
        "])\n",
        "\n",
        "classifier = pipeline.fit(X_train_tok,y_train)\n",
        "predictions = classifier.predict(X_test_tok)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print('Classification report della Logistic Regression:')\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Confusion matrix:')\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X_X626vyIA_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "   \n",
        "\n",
        "    if axes is None:\n",
        "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    axes[0].set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes[0].set_ylim(*ylim)\n",
        "    axes[0].set_xlabel(\"Training examples\")\n",
        "    axes[0].set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes[0].grid()\n",
        "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes[0].legend(loc=\"best\")\n",
        "\n",
        "    # Plot n_samples vs fit_times\n",
        "    axes[1].grid()\n",
        "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
        "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
        "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
        "    axes[1].set_xlabel(\"Training examples\")\n",
        "    axes[1].set_ylabel(\"fit_times\")\n",
        "    axes[1].set_title(\"Scalability of the model\")\n",
        "\n",
        "    # Plot fit_time vs score\n",
        "    axes[2].grid()\n",
        "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
        "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
        "    axes[2].set_xlabel(\"fit_times\")\n",
        "    axes[2].set_ylabel(\"Score\")\n",
        "    axes[2].set_title(\"Performance of the model\")\n",
        "\n",
        "    return plt\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
        "\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "title = \"Learning Curves (OneVsOne(LinearSVC))\"\n",
        "# Cross validation with 100 iterations to get smoother mean test and train\n",
        "# score curves, each time with 20% data randomly selected as a validation set.\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "\n",
        "estimator = OneVsOneClassifier(LinearSVC())\n",
        "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
        "                    cv=cv, n_jobs=4)\n",
        "\n",
        "title = r\"Learning Curves (LogisticRegression)\"\n",
        "\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "estimator = LogisticRegression(solver=\"saga\",multi_class=\"multinomial\", class_weight=\"balanced\")\n",
        "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
        "                    cv=cv, n_jobs=4)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUt69mCryIBB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}